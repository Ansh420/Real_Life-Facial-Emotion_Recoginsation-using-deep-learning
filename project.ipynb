{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        (os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-19T09:07:26.673045Z","iopub.execute_input":"2023-04-19T09:07:26.673445Z","iopub.status.idle":"2023-04-19T09:07:45.468089Z","shell.execute_reply.started":"2023-04-19T09:07:26.673403Z","shell.execute_reply":"2023-04-19T09:07:45.466867Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# import required packages\nimport cv2\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2023-04-19T09:07:53.133141Z","iopub.execute_input":"2023-04-19T09:07:53.133561Z","iopub.status.idle":"2023-04-19T09:08:01.636662Z","shell.execute_reply.started":"2023-04-19T09:07:53.133523Z","shell.execute_reply":"2023-04-19T09:08:01.635416Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_data_gen = ImageDataGenerator(rescale=1./255)\nvalidation_data_gen = ImageDataGenerator(rescale=1./255)","metadata":{"execution":{"iopub.status.busy":"2023-04-19T09:08:29.429748Z","iopub.execute_input":"2023-04-19T09:08:29.430946Z","iopub.status.idle":"2023-04-19T09:08:29.437024Z","shell.execute_reply.started":"2023-04-19T09:08:29.430899Z","shell.execute_reply":"2023-04-19T09:08:29.435642Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_generator = train_data_gen.flow_from_directory(\n        '/kaggle/input/fer2013/train',\n        target_size=(48, 48),\n        batch_size=64,\n        color_mode=\"grayscale\",\n        class_mode='categorical')\n\n# Preprocess all train images\nvalidation_generator = validation_data_gen.flow_from_directory(\n        '/kaggle/input/fer2013/test',\n        target_size=(48, 48),\n        batch_size=64,\n        color_mode=\"grayscale\",\n        class_mode='categorical')\n","metadata":{"execution":{"iopub.status.busy":"2023-04-19T09:09:11.899846Z","iopub.execute_input":"2023-04-19T09:09:11.900598Z","iopub.status.idle":"2023-04-19T09:09:18.802428Z","shell.execute_reply.started":"2023-04-19T09:09:11.900557Z","shell.execute_reply":"2023-04-19T09:09:18.801171Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Found 28709 images belonging to 7 classes.\nFound 7178 images belonging to 7 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"emotion_model = Sequential()\n\nemotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)))\nemotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\nemotion_model.add(MaxPooling2D(pool_size=(2, 2)))\nemotion_model.add(Dropout(0.25))\n\nemotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\nemotion_model.add(MaxPooling2D(pool_size=(2, 2)))\nemotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\nemotion_model.add(MaxPooling2D(pool_size=(2, 2)))\nemotion_model.add(Dropout(0.25))\n\nemotion_model.add(Flatten())\nemotion_model.add(Dense(1024, activation='relu'))\nemotion_model.add(Dropout(0.5))\nemotion_model.add(Dense(7, activation='softmax'))\n\ncv2.ocl.setUseOpenCL(False)","metadata":{"execution":{"iopub.status.busy":"2023-04-19T09:09:25.269702Z","iopub.execute_input":"2023-04-19T09:09:25.270951Z","iopub.status.idle":"2023-04-19T09:09:28.206720Z","shell.execute_reply.started":"2023-04-19T09:09:25.270881Z","shell.execute_reply":"2023-04-19T09:09:28.205622Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"emotion_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-04-19T09:09:40.269899Z","iopub.execute_input":"2023-04-19T09:09:40.270947Z","iopub.status.idle":"2023-04-19T09:09:40.293325Z","shell.execute_reply.started":"2023-04-19T09:09:40.270883Z","shell.execute_reply":"2023-04-19T09:09:40.292091Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super().__init__(name, **kwargs)\n","output_type":"stream"}]},{"cell_type":"code","source":"emotion_model_info = emotion_model.fit_generator(\n        train_generator,\n        steps_per_epoch=28709 // 64,\n        epochs=50,\n        validation_data=validation_generator,\n        validation_steps=7178 // 64)","metadata":{"execution":{"iopub.status.busy":"2023-04-19T09:09:55.419417Z","iopub.execute_input":"2023-04-19T09:09:55.419865Z","iopub.status.idle":"2023-04-19T09:43:54.561062Z","shell.execute_reply.started":"2023-04-19T09:09:55.419825Z","shell.execute_reply":"2023-04-19T09:43:54.559791Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  \n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"2023-04-19 09:09:56.692306: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"448/448 [==============================] - 130s 275ms/step - loss: 1.8046 - accuracy: 0.2581 - val_loss: 1.7204 - val_accuracy: 0.3425\nEpoch 2/50\n448/448 [==============================] - 37s 82ms/step - loss: 1.6336 - accuracy: 0.3634 - val_loss: 1.5381 - val_accuracy: 0.4116\nEpoch 3/50\n448/448 [==============================] - 37s 83ms/step - loss: 1.5233 - accuracy: 0.4165 - val_loss: 1.4535 - val_accuracy: 0.4485\nEpoch 4/50\n448/448 [==============================] - 36s 81ms/step - loss: 1.4452 - accuracy: 0.4474 - val_loss: 1.3942 - val_accuracy: 0.4757\nEpoch 5/50\n448/448 [==============================] - 37s 84ms/step - loss: 1.3832 - accuracy: 0.4740 - val_loss: 1.3418 - val_accuracy: 0.4925\nEpoch 6/50\n448/448 [==============================] - 37s 84ms/step - loss: 1.3287 - accuracy: 0.4974 - val_loss: 1.3128 - val_accuracy: 0.5031\nEpoch 7/50\n448/448 [==============================] - 37s 83ms/step - loss: 1.2840 - accuracy: 0.5133 - val_loss: 1.2586 - val_accuracy: 0.5206\nEpoch 8/50\n448/448 [==============================] - 37s 83ms/step - loss: 1.2426 - accuracy: 0.5328 - val_loss: 1.2331 - val_accuracy: 0.5366\nEpoch 9/50\n448/448 [==============================] - 38s 85ms/step - loss: 1.2141 - accuracy: 0.5398 - val_loss: 1.2048 - val_accuracy: 0.5427\nEpoch 10/50\n448/448 [==============================] - 41s 91ms/step - loss: 1.1846 - accuracy: 0.5555 - val_loss: 1.1887 - val_accuracy: 0.5494\nEpoch 11/50\n448/448 [==============================] - 36s 80ms/step - loss: 1.1536 - accuracy: 0.5675 - val_loss: 1.1730 - val_accuracy: 0.5520\nEpoch 12/50\n448/448 [==============================] - 36s 81ms/step - loss: 1.1252 - accuracy: 0.5774 - val_loss: 1.1617 - val_accuracy: 0.5537\nEpoch 13/50\n448/448 [==============================] - 37s 83ms/step - loss: 1.0974 - accuracy: 0.5879 - val_loss: 1.1400 - val_accuracy: 0.5646\nEpoch 14/50\n448/448 [==============================] - 36s 80ms/step - loss: 1.0742 - accuracy: 0.5993 - val_loss: 1.1271 - val_accuracy: 0.5713\nEpoch 15/50\n448/448 [==============================] - 36s 80ms/step - loss: 1.0506 - accuracy: 0.6097 - val_loss: 1.1244 - val_accuracy: 0.5709\nEpoch 16/50\n448/448 [==============================] - 36s 80ms/step - loss: 1.0310 - accuracy: 0.6134 - val_loss: 1.1058 - val_accuracy: 0.5791\nEpoch 17/50\n448/448 [==============================] - 39s 88ms/step - loss: 1.0023 - accuracy: 0.6272 - val_loss: 1.1082 - val_accuracy: 0.5882\nEpoch 18/50\n448/448 [==============================] - 38s 84ms/step - loss: 0.9833 - accuracy: 0.6354 - val_loss: 1.0913 - val_accuracy: 0.5862\nEpoch 19/50\n448/448 [==============================] - 37s 82ms/step - loss: 0.9593 - accuracy: 0.6439 - val_loss: 1.0983 - val_accuracy: 0.5857\nEpoch 20/50\n448/448 [==============================] - 38s 84ms/step - loss: 0.9375 - accuracy: 0.6525 - val_loss: 1.0887 - val_accuracy: 0.5931\nEpoch 21/50\n448/448 [==============================] - 37s 83ms/step - loss: 0.9165 - accuracy: 0.6622 - val_loss: 1.0745 - val_accuracy: 0.5981\nEpoch 22/50\n448/448 [==============================] - 36s 81ms/step - loss: 0.8942 - accuracy: 0.6681 - val_loss: 1.0764 - val_accuracy: 0.5975\nEpoch 23/50\n448/448 [==============================] - 37s 83ms/step - loss: 0.8715 - accuracy: 0.6757 - val_loss: 1.0729 - val_accuracy: 0.6023\nEpoch 24/50\n448/448 [==============================] - 37s 82ms/step - loss: 0.8501 - accuracy: 0.6894 - val_loss: 1.0717 - val_accuracy: 0.6042\nEpoch 25/50\n448/448 [==============================] - 37s 82ms/step - loss: 0.8271 - accuracy: 0.6925 - val_loss: 1.0840 - val_accuracy: 0.5988\nEpoch 26/50\n448/448 [==============================] - 38s 84ms/step - loss: 0.7987 - accuracy: 0.7067 - val_loss: 1.0732 - val_accuracy: 0.6070\nEpoch 27/50\n448/448 [==============================] - 36s 81ms/step - loss: 0.7804 - accuracy: 0.7135 - val_loss: 1.0686 - val_accuracy: 0.6080\nEpoch 28/50\n448/448 [==============================] - 36s 80ms/step - loss: 0.7592 - accuracy: 0.7228 - val_loss: 1.0708 - val_accuracy: 0.6083\nEpoch 29/50\n448/448 [==============================] - 36s 81ms/step - loss: 0.7367 - accuracy: 0.7304 - val_loss: 1.0735 - val_accuracy: 0.6109\nEpoch 30/50\n448/448 [==============================] - 36s 80ms/step - loss: 0.7078 - accuracy: 0.7409 - val_loss: 1.0716 - val_accuracy: 0.6110\nEpoch 31/50\n448/448 [==============================] - 37s 82ms/step - loss: 0.6840 - accuracy: 0.7519 - val_loss: 1.0721 - val_accuracy: 0.6164\nEpoch 32/50\n448/448 [==============================] - 36s 80ms/step - loss: 0.6627 - accuracy: 0.7590 - val_loss: 1.0846 - val_accuracy: 0.6117\nEpoch 33/50\n448/448 [==============================] - 34s 77ms/step - loss: 0.6501 - accuracy: 0.7622 - val_loss: 1.0816 - val_accuracy: 0.6152\nEpoch 34/50\n448/448 [==============================] - 35s 78ms/step - loss: 0.6258 - accuracy: 0.7734 - val_loss: 1.1030 - val_accuracy: 0.6095\nEpoch 35/50\n448/448 [==============================] - 36s 81ms/step - loss: 0.6010 - accuracy: 0.7838 - val_loss: 1.0934 - val_accuracy: 0.6133\nEpoch 36/50\n448/448 [==============================] - 35s 79ms/step - loss: 0.5809 - accuracy: 0.7900 - val_loss: 1.0999 - val_accuracy: 0.6217\nEpoch 37/50\n448/448 [==============================] - 34s 76ms/step - loss: 0.5628 - accuracy: 0.7945 - val_loss: 1.1065 - val_accuracy: 0.6198\nEpoch 38/50\n448/448 [==============================] - 34s 76ms/step - loss: 0.5460 - accuracy: 0.8024 - val_loss: 1.1179 - val_accuracy: 0.6197\nEpoch 39/50\n448/448 [==============================] - 38s 85ms/step - loss: 0.5232 - accuracy: 0.8127 - val_loss: 1.1268 - val_accuracy: 0.6217\nEpoch 40/50\n448/448 [==============================] - 38s 85ms/step - loss: 0.5120 - accuracy: 0.8133 - val_loss: 1.1311 - val_accuracy: 0.6212\nEpoch 41/50\n448/448 [==============================] - 35s 77ms/step - loss: 0.4883 - accuracy: 0.8229 - val_loss: 1.1333 - val_accuracy: 0.6214\nEpoch 42/50\n448/448 [==============================] - 40s 89ms/step - loss: 0.4778 - accuracy: 0.8265 - val_loss: 1.1582 - val_accuracy: 0.6212\nEpoch 43/50\n448/448 [==============================] - 35s 78ms/step - loss: 0.4543 - accuracy: 0.8373 - val_loss: 1.1502 - val_accuracy: 0.6244\nEpoch 44/50\n448/448 [==============================] - 34s 76ms/step - loss: 0.4435 - accuracy: 0.8398 - val_loss: 1.1457 - val_accuracy: 0.6190\nEpoch 45/50\n448/448 [==============================] - 35s 77ms/step - loss: 0.4251 - accuracy: 0.8485 - val_loss: 1.1629 - val_accuracy: 0.6218\nEpoch 46/50\n448/448 [==============================] - 34s 76ms/step - loss: 0.4206 - accuracy: 0.8492 - val_loss: 1.1732 - val_accuracy: 0.6212\nEpoch 47/50\n448/448 [==============================] - 34s 76ms/step - loss: 0.3998 - accuracy: 0.8583 - val_loss: 1.1845 - val_accuracy: 0.6270\nEpoch 48/50\n448/448 [==============================] - 39s 87ms/step - loss: 0.3894 - accuracy: 0.8618 - val_loss: 1.1953 - val_accuracy: 0.6258\nEpoch 49/50\n448/448 [==============================] - 35s 77ms/step - loss: 0.3827 - accuracy: 0.8624 - val_loss: 1.1845 - val_accuracy: 0.6237\nEpoch 50/50\n448/448 [==============================] - 36s 80ms/step - loss: 0.3652 - accuracy: 0.8679 - val_loss: 1.2378 - val_accuracy: 0.6295\n","output_type":"stream"}]},{"cell_type":"code","source":"model_json = emotion_model.to_json()\nwith open(\"emotion_model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n\n# save trained model weight in .h5 file\nemotion_model.save_weights('emotion_model.h5')","metadata":{"execution":{"iopub.status.busy":"2023-04-19T09:44:37.728047Z","iopub.execute_input":"2023-04-19T09:44:37.728450Z","iopub.status.idle":"2023-04-19T09:44:37.774794Z","shell.execute_reply.started":"2023-04-19T09:44:37.728415Z","shell.execute_reply":"2023-04-19T09:44:37.773655Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-04-19T10:27:47.270762Z","iopub.execute_input":"2023-04-19T10:27:47.271510Z","iopub.status.idle":"2023-04-19T10:27:55.973643Z","shell.execute_reply.started":"2023-04-19T10:27:47.271479Z","shell.execute_reply":"2023-04-19T10:27:55.972436Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}